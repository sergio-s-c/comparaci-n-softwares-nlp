<!DOCTYPE html>
<html>

<head lang="es">
	<meta charset="utf-8">
	<title>Trabajo en grupo TG1</title>
	<style>
		table,
		th,
		td {
			border: 1px solid black;
			text-align: left;			
		}
	</style>
</head>

<body>
	<header>
		<h1>Desarrollo con Tecnologías Emergentes. Curso 2020-21<br>
			Trabajo TG1 del grupo 10<br>
			Título: Recursos sobre dos tecnologías emergentes para: Natural Languages Processing Libraries<br>
			Tecnologías: SpaCy y NLTK</h1>
	</header>
	<nav>
		<ul>
			<li><a href="#1">1. Información general</a></li>
			<li><a href="#2">2. SpaCy </a></li>
			<ul>
				<li><a href="#2.1">2.1. Cursos</a></li>
				<li><a href="#2.2">2.2. Documentos</a></li>
				<li><a href="#2.3">2.3. Software</a></li>
			</ul>
			<li><a href="#3">3. NLTK </a></li>
			<ul>
				<li><a href="#3.1">3.1. Cursos</a></li>
				<li><a href="#3.2">3.2. Documentos</a></li>
				<li><a href="#3.3">3.3. Software</a></li>
			</ul>
			<li><a href="#4">4. Conclusiones</a></li>
		</ul>
	</nav>

	<main>
		
		<section id=1">
			<h2>1. Información general</h2>
			<table>
				<tr>
					<th>AUTORES</th>
					<td>Sergio Sánchez Campo, David Ramos Fernández.</td>
				</tr>
				<tr>
					<th>PROYECTO SCRUM Y REPOSITORIO EN GITLAB.COM</th>
					<td>
						<a href="https://gitlab.com/dte2021g10/tg1/">https://gitlab.com/dte2021g10/tg1/</a>
					</td>
				</tr>
				<tr>
					<th>TRABAJO PUBLICADO EN GITLAB.IO</th>
					<td>
						<a href="https://dte2021g10.gitlab.io/tg1/tg1.html">https://dte2021g10.gitlab.io/tg1/tg1.html</a>
					</td>
				</tr>
				<tr>
					<th>BURNDOWN CHART</th>
					<td><br>
						<img src="burndownTG1.jpg" width="1388" height="517">
					</td>
				</tr>
				<tr>
					<th>PRESENTACIÓN DEL TRABAJO</th>
					<td>Enlace al archivo de la presentación con diapositivas, ubicada en Office 365 de la UAH.
						<a href="https://universidaddealcala-my.sharepoint.com/:p:/g/personal/david_ramosf_edu_uah_es/EZTav__Mxl1Il7RILTU0g3YB816QC0qr3Jt0KsCibBs2dg">Presentación TG1</a>
					</td>
				</tr>
				<tr>
					<th>CATEGORÍA DE LAS TECNOLOGÍAS</th>
					<td> Las tecnologías seleccionadas pertenecen a la categoría del Procesamiento del lenguaje natural (Natural Lenguaje Processing). Esta categoría pertenece al campo de la inteligencia artificial
						y se centra en la comunicación entre las máquinas y las personas mediante el uso de los idiomas tanto escritos como en voz. Para que la máquina pueda entender, interpretar y procesar el lenguaje humano, se utilizan
						una serie de modelos de aprendizaje automático, que den la capacidad a la máquina de traducir el lenguaje humano al suyo, modelos lógicos basados en la gramática donde la máquina aprenda los patrones estructurales
						del lenguaje humano y modelos probabilisticos del lenguaje natural basado en datos para dar capacidad a la máquina de predecir el contexto donde se produce la comunicación. 
						</td>
				</tr>
			</table>
		</section>

		<section id="2">
			<h2>2. SpaCy </h2>
			<h3 id=2.1>2.1 Cursos</h3>
			<h4>2.1.1 Curso 1</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>Sergio Sánchez Campo</td>
				</tr>
				<tr>
					<th>TÍTULO DEL CURSO</th>
					<td>Advanced NLP with spaCy</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>Se enseña a emplear spaCy para la creación de sistemas avanzados de comprensión del lenguaje natural,
						 empleando tanto sistemas basados en reglas como machine learning. Los principales temas que se enseñarán serán: localización de palabras, frases, nombres y conceptos. Además del análisis de grandes cantidades de datos, el procesamiento de pipelines y su posterior entrenamiento mediante un modelo de red neuronal.</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td><p>1.Finding words, phrases,names and concepts</p>
						<p>2.Large-scale data análisis with spaCy</p>
						<p>3.Processing Pipelines</p>
						<p>4.Training a neural network model</p>
						</td>
				</tr>
				<tr>
					<th>DURACIÓN</th>
					<td>5 horas</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td>21,28 euros</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Porque mediante este curso puedes aprender todas las funciones básicas de spaCy y como emplearlo adecuadamente, esto resulta de gran utilidad ya que se trata de una librería estándar de Python para NLP que está presentado un rápido crecimiento y es una de las más empleadas en el ámbito del procesamiento de lenguaje natural.</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador Google, escribiendo courses for SpaCy.</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href="https://www.datacamp.com/courses/advanced-nlp-with-spacy?fbclid=IwAR0GoQjDzEZGtcup_E1mwbUvVEhYFCcc_Uidwm3Up8lGF3ePoEd6lRFPeeE">https://www.datacamp.com/courses/advanced-nlp-with-spacy?fbclid=IwAR0GoQjDzEZGtcup_E1mwbUvVEhYFCcc_Uidwm3Up8lGF3ePoEd6lRFPeeE</a>></td>
				</tr>
			</table>
			<h4>2.1.2 Curso 2</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>David Ramos Fernández</td>
				</tr>
				<tr>
					<th>TÍTULO DEL CURSO</th>
					<td>Curso de Natural Language Processing (NLP) with Python spaCy</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>Los objetivos de este curso es apreder a realizar una serie de acciones utilizando la biblioteca
						spaCY como por ejemplo la integracion de spaCy en una aplicación web o para usarlo en el postprocesado
						de textos para Deep Learning. Además, en el curso se enseñará a como instalar y configurar spaCy y este 
						puede realizarse de forma online, la cual se podrá elegir si realizarla de forma particular o en un grupo 
						o en formato presencial. Este curso esta orientado para desarrolladores y cientificos de datos y se debe
						tener conocimientos en python, conceptos básicos de estadística y experiencia con lineas de comando. 
					</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td>
				
					<p>	1. Introduction</p>
					<ul> <li>Defining "Industrial-Strength Natural Language Processing"</li></ul>
					<p>2. Installing spaCy</p>
					<p>3. Overview of spaCy Features and Syntax</p>
					<p>4. Understanding spaCy Modeling</p>
					<ul>	<li> Statistical modeling and prediction</li></ul>
					<p>5. Using the SpaCy Command Line Interface (CLI)</p>
					<ul> 		<li>Basic commands</li></ul>
					<p>6. Creating a Simple Application to Predict Behavior</p>
					<p>7. Training a New Statistical Model</p>
					<ul>	<li>Data (for training)</li> </ul>
					<ul>	<li>Labels (tags, named entities, etc.)</li> </ul>
					<p>8. Loading the Model</p>
					<ul>		<li>Shuffling and looping</li> </ul>
					<p>9. Saving the Model</p>
					<p>10. Providing Feedback to the Model</p>
					<ul>		<li>Error gradient</li> </ul>
					<p>11. Updating the Model</p>
					<ul>	<li>Updating the entity recognizer</li> </ul>
					<ul>	<li>Tokens with rule-based matcher</li> </ul>
					<p>12. Developing a Generalized Theory for Expected Outcomes</p>
					<p>13. Case Study </p>
					<ul>	<li>Distinguishing Product Names from Company Names</li> </ul>
					<p>14. Refining the Training Data</p>
					<ul>	<li>Selecting representative data</li> </ul>
					<ul>	<li>Setting the dropout rate</li></ul>
					<p>15. Other Training Styles</p>
					<ul>	<li>Passing raw texts</li> </ul>
					<ul>	<li>Passing dictionaries of annotations</li> </ul>
					<p>16. Using spaCy to Pre-process Text for Deep Learning</p>
					<p>17. Integrating spaCy with Legacy Applications</p>
					<p>18. Testing and Debugging the spaCy Model</p>
					<ul>	<li> The importance of iteration</li> </ul>
					<p>19. Deploying the Model to Production</p>
					<p>20. Monitoring and Adjusting the Model</p>
					<p>21. Troubleshooting</p>
					<p>22. Summary and Conclusion</p>
					</td>
				
				</tr>
				<tr>
					<th>DURACIÓN</th>
					<td>14 horas (repartidas en 2 días)</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td> <p>En grupo online: 1025€</p>
						<p>En privado online: desde 1700€</p>
						<p>En privado presencial: desde 2300€</p>
					</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Este curos es útil para iniciarse en la tecnología spaCY y aplicarla a un entorno empresarial, mas concretamente en el área de los servicios web, ya que 
						este curso nos ensaña a realizar la instalación y configuración de la tecnología, los conceptos básicos del funcionamiento de la tecnología, extracción de 
						patrones y obtención de Información a gran escala, integración de la tecnología en aplicaciones web, predicción del comportamiento humano y preprocesado de texto
						para su uso en Deep Learning.
					</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador de Google, buscando cursos de spaCy</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href=https://www.nobleprog.es/cc/spacy?participants=4&how=public> https://www.nobleprog.es/cc/spacy?participants=4&how=public</a></td>
				</tr>
			
			</table>

			<h3 id=2.2>2.2 Documentos (Artículos, libros, foros, blogs)</h3>
			<h4>2.2.1 Documento 1</h4>
			<table>
				<tr>
					<th>ANALISTA</td>
					<td>Sergio Sánchez Campo</td>
				</tr>
				<tr>
					<th>TÍTULO</th>
					<td>Enhancing the spaCy named entity recognizer for crowdsensing</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>En este artículo se analiza el named entity recognizer (NER) de spaCy, orientado a la identificación de identidades o lugares mencionadas en un texto a partir de microtextos españoles obtenidos de redes sociales. Este NER funciona mediante redes neuronales artificales y mediante los resultados obtenidos se deriva que se necesita un aprendizaje mucho mayor para incrementar su precisión. Además también se observó que presentaba una precisión mucho menor cuando analizaba documentos que procedían de dominios diferentes respecto a los dominios con los que había sido entrenado.
						Para solucionar este problema se desarrolló una herramienta de generación de textos automáticos para el entrenamiento del NER, que estaban basados en microtextos de Twitter en español. Como resultado del entrenamiento con dichos datos se obtuvo un incremento en la precisión de un 0,7 F-score, un valor superior al que se obtiene al entrenarlo con un conjunto de datos clásicos como AnCora, WIKINER o CONLL.
						</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td><p>1.Introduction</p>
						<p>2.Method</p>
						<p><ul>2.1spaCy Named Entity Recognizer</ul></p>
						<p><ul>2.2 Dataset generation for training</ul></p>
						<p><ul>2.3 Training procedure</ul></p>
						<p>3.Evaluation</p>
						<p>4.Conclusions and future work</p>
						<p>5.Acknowledgments</p>
						<p>	6.References</p>


					</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Es útil porque nos muestra una forma de entrenamiento alternativa para la función del reconocimiento de named-entity que se ha demostrado que es ventajosa en comparación con otros conjuntos clásicos de datos que son ampliamente usados para el proceso de entrenamiento. Lo cual nos permitirá tener una mayor información a la hora de seleccionar 
						fuentes para entrenar a nuestro programa y así poder obtener una mayor precisión.</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Buscando artículos relacionados con la tecnología spaCy en el buscador Google Scholar.</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href="https://books.google.es/books?hl=es&lr=&id=GJP-DwAAQBAJ&oi=fnd&pg=PA361&dq=spacy+&ots=VfgtsYAXA6&sig=r1s2KX4xlfmj-qaD0BP5pAN65xM#v=onepage&q=spacy&f=false">https://books.google.es/books?hl=es&lr=&id=GJP-DwAAQBAJ&oi=fnd&pg=PA361&dq=spacy+&ots=VfgtsYAXA6&sig=r1s2KX4xlfmj-qaD0BP5pAN65xM#v=onepage&q=spacy&f=false</a></td>
				</tr>
			</table>
			<h4>2.2.2 Documento 2</h4>
			<table>
				<tr>
					<th>ANALISTA</td>
					<td>David Ramos Fernández</td>
				</tr>
				<tr>
					<th>TÍTULO</th>
					<td>Polarity Detection in a Cross-Lingual Sentiment Analysis using spaCy</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>En este documento se realiza una comparación de los análisis de sentimiento de unos tweets en francés y los mismos tweets traducidos al inglés
						utilizando una serie de técnicas para preparar los datos de entrenamiento y posteriormente se realiza el aprendizaje automático utilizando los algoritmos
						de regresión lógica, Naïve Bayes y el descenso de gradiente estocástico .Para ello se utiliza la biblioteca spaCy ya que tiene la capacidad de realizar 
						análisis de sentimiento en multiples idiomas.
					</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td>
						<p>1.Introduction</p>
						<p>2.Previous Works</p>				
						<p>3.Corpus Used</p>						
						<p>4.Research Pipeline</p>						
						<p>5.Preparation of Data</p>						
						<p>6.N-Grams Extraction</p>						
						<p>7.Machine Learning Models</p>						
						<p>8.Performance Evaluation</p>						
						<p>9.Results and Discussion</p>						
						<p>10.Conclusion</p>						
						<p>11.Future Scope</p>
					</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Este documento aporta conocimientos sobre las áreas de análisis de sentimientos en distintos idiomas al inglés, la confiabilidad de las herramientas de traducción
						automática para la realización del análisis de sentimientos en varios idiomas y una evaluación de spaCy para realizar análisis de sentimientos multilingües. </td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador de Microsoft Academic, buscando articulos relacionados con spaCy</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href=https://ieeexplore.ieee.org/document/9197829> https://ieeexplore.ieee.org/document/9197829</a></td>
				</tr>	
					
			</table>

			<h3 id=2.3>2.3 Software (herramientas, editores, etc. para desarrollar con la tecnología)</h3>
			<h4>2.3.1 Software 1</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>Sergio Sánchez Campo</td>
				</tr>
				<tr>
					<th>NOMBRE</th>
					<td>displaCy</td>
				</tr>
				<tr>
					<th>PARA QUÉ SIRVE</th>
					<td>Se trata de un visualizador para SpaCy que muestra la estructura sintáctica de la oración, además de su dependencia sintáctica mediante flechas etiquetadas que muestran cada tipo de relación en la frase.</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td>Gratuito</td>
				</tr>
				<tr>
					<th>LICENCIA DE USO</th>
					<td>Presenta MIT License.Copyright (C) 2016 ExplosionAI UG (haftungsbeschränkt)
						
						<p>Se trata de una licencia permisiva que solo requiere de la preservación de los avisos de licencia y derechos de autor.
						Permite el uso comercial, la modificación, su distribución y su uso privado. Está limitada su responsabilidad y garantía. Y exige que se avise de su licencia y copyright.</p>
						</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Buscando tools for Spacy en Google.</td>
				</tr>
				<tr>
					<th>URL SOFTWARE</th>
					<td><a href="https://github.com/explosion/displacy">https://github.com/explosion/displacy</a></td>
				</tr>
				<tr>
					<th>URL GUÍA DE USO</th>
					<td>
						<a href="https://spacy.io/usage/visualizers">https://spacy.io/usage/visualizers</a>
						<p><a href="https://spacy.io/api/top-level#displacy.serve">https://spacy.io/api/top-level#displacy.serve</a></p>
							<p><a href="https://explosion.ai/blog/displacy-js-nlp-visualizer">https://explosion.ai/blog/displacy-js-nlp-visualizer</a></p>
								<p><a href="https://github.com/explosion/displacy">https://github.com/explosion/displacy</a></p>

					</td>
				</tr>
			</table>
			<h4>2.3.2 Software 2</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>David Ramos Fernández</td>
				</tr>
				<tr>
					<th>NOMBRE</th>
					<td>Prodigy</td>
				</tr>
				<tr>
					<th>PARA QUÉ SIRVE</th>
					<td>Prodigy es una herramienta que ayuda a los cientificos de datos a entrenar modelos de aprendizaje supervisados permitiendo una
						interacción rápida en la identificación de entidades, la detección de intenciones o la clasificación de imagenes. Tambien permite 
						la transmisión de ejemplos propios o de datos reales desde la API en vivo, permite actualizar el modelo en tiempo real y encadenar
						modelos para construir sistemas mas complejos. 
					</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td><p>Personal: 390$/año por licencia</p>
						<p>Empresa: 490$/año por asiento (se vende en paquetes de 5 asientos) </p>
					</td>
				</tr>
				<tr>
					<th>LICENCIA DE USO</th>
					<td>
						<p>Copyright (C) 2016-2021 ExplosionAI GmbH, 2016 spaCy GmbH, 2015 Matthew Honnibal.</p>
						<p>PERMISOS (resumido): Uso comercial por tiempo ilimitado. </p>
						<p>LIMITACIONES (resumido):No se puede distribuir, no se puede modificar, no se permite la instalación en servidores públicos, no tiene garantía </p>
						<p><a href=https://prodi.gy/terms>Documento de la licencia</a></p>
					</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador de Google, buscando herramientas que utilizan spaCy</td>
				</tr>
				<tr>
					<th>URL SOFTWARE</th>
					<td><a href=https://prodi.gy> https://prodi.gy</a></td>
				</tr>
				<tr>
					<th>URL GUÍA DE USO</th>
					<td><a href=https://prodi.gy/docs> https://prodi.gy/terms</a></td>
				</tr>
			</table>		
		</section>

		<section id="3">
			<h2>3. NLTK</h2>						
			<h3 id=3.1>3.1 Cursos</h3>
			<h4>3.1.1 Curso 1</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>Sergio Sánchez Campo</td>
				</tr>
				<tr>
					<th>TÍTULO DEL CURSO</th>
					<td>From Zero to Hero: Natural Language Processing Using NLTK</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>Se trata de un curso para formarse en el procesamiento de lenguaje natural en Python mediante el empleo de la librería NLTK, una de las librerías más importantes en este ámbito.
						Orientado a usuarios que tienen conocimientos básicos de Python y que conocen poco o no conocen sobre la librería NLTK.
						 Los objetivos básicos de este curso es permitir a los usuarios aprender todos y cada uno de los aspectos báscios de NLTK en la menor cantidad de tiempo posible. Como aprender a trabajar con datos en texto, tener un conocimiento completo sobre la librería NLTK, aprender sobre los analizadores de sentimientos prácticos y a programar generadores automáticos de resúmenes de un texto.
						</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td><p>1.Introduction
						<p><ul>1.1.Introduction</ul>
							<p><ul>1.2.Environment Set Up</ul>

						<p>2.Pre-Processing Techniques</p>
						<p><ul>2.1.Tokenization</p></ul>
							<p><ul>2.2.StopWords</p></ul>
								<p><ul>2.3.Stemming</p></ul>
									<p><ul>2.4.Lemmatization</p></ul>

						<p>3.Advanced Pre-Processing Techniques</p>
						<p><ul>3.1.Parts of Speech Tagging</p></ul>
							<p><ul>3.2.Chunking-Part 1</p></ul>
								<p><ul>3.3.Chunking-Part 2</p></ul>
									<p><ul>3.4.Chinking</p></ul>
										<p><ul>3.5.Named Entity Recognition</p></ul>
											<p><ul>3.6.Wordnet-Part 1</p></ul>
												<p><ul>3.7.Wordnet-Part 2</p></ul>

						<p>4.Classification Algorithm</p>
						<p><ul>4.1.Text Classification-Part 1</p></ul>
							<p><ul>4.2. Text Classification-Part 2</p></ul>
								<p><ul>4.3.Word as a feature for learning</p></ul>
									<p><ul>4.4.Integrating Naive Bayes Classifier with NLTK</p></ul>
										<p><ul>	4.5.Pickling</p></ul>
											<p><ul>4.6.Integrating Sci-Kit Classifiert with NLTK-Part1</p></ul>
												<p><ul>	4.7. Integrating Sci-Kit Classifiert with NLTK-Part1</p></ul>

						<p>5.Capstone Project</p>
						<p><ul>	5.1.Introduction</p></ul>
							<p><ul>5.2.Part-1</p></ul>
								<p><ul>	5.3.Part-2</p></ul>

						</td>
				</tr>
				<tr>
					<th>DURACIÓN</th>
					<td>1 hora y 23 minutos</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td>19,99 €</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Porque con este curso se pueden aprender todos los aspectos básicos y fundamentales de la librería NLTK en el menor tiempo posible. Permitiendo al usuario formarse en el uso de esta herramienta en menos de 2 horas y a un precio muy asequible.</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Buscando: Courses for NLTK en el buscador Google.</td>
				</tr>
				<tr>
					<th>URL</th>
					<td>
					<a href="https://www.udemy.com/course/from-zero-to-hero-natural-language-processing-using-nltk/?ranMID=39197&ranEAID=k*VTdGlCbXg&ranSiteID=k.VTdGlCbXg-erzjpnBkACPXIbSCfZRuaw&utm_source=aff-campaign&LSNPUBID=k*VTdGlCbXg&utm_medium=udemyads">https://www.udemy.com/course/from-zero-to-hero-natural-language-processing-using-nltk/?ranMID=39197&ranEAID=k*VTdGlCbXg&ranSiteID=k.VTdGlCbXg-erzjpnBkACPXIbSCfZRuaw&utm_source=aff-campaign&LSNPUBID=k*VTdGlCbXg&utm_medium=udemyads</a>	
					</td>
				</tr>
			</table>
			<h4>3.1.2 Curso 2</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>David Ramos Fernández</td>
				</tr>
				<tr>
					<th>TÍTULO DEL CURSO</th>
					<td>Procesamiento del Lenguaje Natural con Python (NLP) [2021]</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>En este curso se enseña a realizar sistemas NLP desde cero,
						a la realizar análisis de sentimientos, aprender a usar python desde 0 y sus aplicaciones en NLP
						, construir modelos de clasificación de textos con NLTk, crear chatbots y construir un sistema de reconocimiento y 
						síntesis de voz.
					</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td><p>	1. Introduction al procesamiento del lenguaje natural (NLP)</p>
						<ul><li>¿Qué es el Procesamiento del Lenguaje Natural (NLP)?</li></ul>
						<ul><li>Aplicaciones del procesamiento del Lenguaje Natural</li> </ul>
						<p>2. Introducción a python (Opcional)</p>
						<ul><li>Instalación Python + Jupyter</li> </ul>
						<ul><li>Conceptos básicos de Python</li></ul>
						<ul> <li>Introducción a las librerías: Numpy</li> </ul>
						<ul><li>Introducción a las librerías: Pandas</li></ul>
						<ul><li>Introducción a las librerías: Matplotlib</li> </ul>
						<p>3. Sistema de clasificación de textos</p>
						<ul> <li>¿En qué consiste la Clasificación de textos?</li></ul>
						<ul> <li>Instalación librería NLTK</li></ul>
						<ul> <li> Práctico Clasificación de textos - Tokenizar</li></ul>
						<ul> <li>Práctico Clasificación de textos - Palabras de Parada</li> </ul>
						<ul> <li>Caso Práctico Clasificación de textos - Sinónimos y antónimos</li></ul>
						<ul> <li>Práctico Clasificación de textos - Derivación Regresiva</li></ul>
						<ul> <li>Práctico Clasificación de textos - Lematización</li> </ul>
						<ul> <li>Caso de uso Clasificación de textos - Filtro Spam</li></ul>
						<p>4. Análisis de sentimientos</p>
						<ul><li>¿En que consiste el Análisis de sentimientos?</li></ul>
						<ul><li>Caso Prácticos Twitter - Conexión y captura de tweets</li></ul>
						<ul><li>Caso Prático Twitter - Análisis y visualización de sentimientos</li></ul>
						<p>5. Creación de chatbot</p>
						<ul> <li>Práctico Creación Chatbot - Definición Corpus</li></ul>
						<ul><li>Práctico Creación Chatbot - Preprocesamiento del Texto</li></ul>
						<ul><li>Caso Práctico Creación Chatbot - Evaluación de similidad</li></ul>
						<ul><li>Práctico Creación Chatbot - Definición de coincidencias manuales</li></ul>
						<ul><li>Caso Práctico Creación Chatbot - Generación de respuestas y diálogo con chatbot</li></ul>
						<p>6. Reconocimiento y Síntesis de voz</p>
						<ul><li>¿En qué consiste el Reconocimiento y Síntesis de Voz?</li></ul>
						<ul><li>Instalación de Librerías SpeechRecognition / PyAudio</li></ul>
						<ul><li>Práctico - Reconocimiento de voz con Python</li></ul>
						<ul><li>Combinación de funcionalidades NLP para crear herramientas integrales</li></ul>
						<p>7. Conclusiónes</p>
						<p>8.Clase Extra NLP</p></td>
				</tr>
				<tr>
					<th>DURACIÓN</th>
					<td>2h 33 min</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td>69,99€</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Este curso es útil para personas sin experiencia en python ni en la tecnología NLP, ya que este curso 
						explica los conceptos básicos sobre el uso de python para poder comenzar a aprender a utilizar la 
						 NTLK sin tener conocimientos previos del mismo.
					</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador de Google, buscado cursos de NLTK</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href=https://www.udemy.com/course/procesamiento-del-lenguaje-natural-con-python-nlp/?ranMID=39197&ranEAID=k*VTdGlCbXg&ranSiteID=k.VTdGlCbXg-yDhI57uwbLamNWLJxwNL5Q&LSNPUBID=k*VTdGlCbXg&utm_source=aff-campaign&utm_medium=udemyads> https://www.udemy.com/course/procesamiento-del-lenguaje-natural-con-python-nlp/?ranMID=39197&ranEAID=k*VTdGlCbXg&ranSiteID=k.VTdGlCbXg-yDhI57uwbLamNWLJxwNL5Q&LSNPUBID=k*VTdGlCbXg&utm_source=aff-campaign&utm_medium=udemyads</a></td>
				</tr>
			</table>			
			<h3 id=3.2>3.2 Documentos (Artículos, libros, foros, blogs)</h3>
			<h4>3.2.1 Documento 1</h4>
			<table>
				<tr>
					<th>ANALISTA</td>
					<td>Sergio Sánchez Campo</td>
				</tr>
				<tr>
					<th>TÍTULO</th>
					<td>NLTK: The Natural Language Toolkit</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>En este artículo se describe un nuevo enfoque de enseñanza de la introducción a la lingüística computacional de una manera ágil y flexible, mediante el empleo de NLTK. A lo largo del artículo se analizan los diferentes requerimientos y características que debe cumplir el sistema para lograr este fin de la forma más óptima posible. Además, enumera y describe diversos módulos que ayudan a esta tarea, como los módulos de visualización o módulos de análisis. Junto con una amplia variedad de ejemplos de usos del NLTK orientados a facilitar y complementar su aprendizaje. </td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td>
						<p>1.Introduction</p>
							<p>2.Choice of Programming Language</p>
								<p>3. Design Criteria</p>
									<ul><p>3.1 Requirements</p></ul>
										<ul>	<p>3.2 Non-Requirements</p></ul>
											<p>4. Modules</p>
												<p>5. Documentation</p>
													<p>6. Uses of NLTK</p>
													<ul>	<p>6.1 Assignments</p></ul>
													<ul>	<p>6.2 Class demonstrations</p></ul>
														<ul><p>6.3 Advanced Projects</p></ul>
																	<p>7. Evaluation</p>
																		<p>8. Other Approaches</p>
																			<p>9. Conclusions and Future Work</p>
																				<p>10. Acknowledgments</p>
																					<p>11. References</p>

					</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Porque gracias a este artículo se pueden aprender nuevos métodos de enseñanza y aprendizaje de la lingüística computacional mediante el empleo del NLTK, además de describir cuales son las características más relevantes que debe cumplir el sistema para estar correctamente adaptado y adecuado a la enseñanza. Y de esta manera lograr ofrecer una formación más óptima y dirigida a entornos de trabajo real.</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Buscando artículos sobre NLTK en el buscador Google Scholar</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href="https://arxiv.org/pdf/cs/0205028.pdf">https://arxiv.org/pdf/cs/0205028.pdf</a></td>
				</tr>
			</table>
			<h4>3.2.2 Documento 2</h4>
			<table>
				<tr>
					<th>ANALISTA</td>
					<td>David Ramos Fernández</td>
				</tr>
				<tr>
					<th>TÍTULO</th>
					<td>Sentiment Analysis of Twitter Data using NLTK in Python</td>
				</tr>
				<tr>
					<th>RESUMEN</th>
					<td>Este documento trata sobre el analisis de sentimientos a partir de los datos extraidos de twitter. 
						Se utilizará el kit de herramientas de NLTK,para poder clasificar los datos de Twitter en
						sentimientos positivos o negativos mediante el uso de diferentes modelos de aprendizaje automático supervisado 
						los cuales se compararan para ver cual es el mejor modelo para este análisis.
					</td>
				</tr>
				<tr>
					<th>ÍNDICE DE CONTENIDOS</th>
					<td>
						<p>	Chapter 1: Introduction</p>
						<ul>	1.1 Indtroduction to Sentiment Analysis</ul>
						<ul>	1.2 Introduction to Python</ul>
						<ul>	1.3 Introduction to NLTK</ul>
						<ul>	1.4 Introduction to Supervised Machine learning Classifiers</ul>
						<ul>	<ul>	1.4.1 Naïve-Bayes (NB) Classifier</ul></ul>
						<ul>	<ul>	1.4.2 MultinominalNB Classifier</ul></ul>
						<ul>	<ul>	1.4.3 BernoulliNB Classifier</ul></ul>
						<ul>	<ul>	1.4.4 Logistic Regresion Classifier</ul></ul>
						<ul>	<ul>	1.4.5 SGDC (Stochastic Gradient Decent Classifier)</ul></ul>
						<ul>	<ul>	1.4.6 SVC (Support Vector Classifier): LinearSVC and NuSVC</ul></ul>
						<ul>	1.5 Goal of Theasis </ul>
						<ul>1.6 Need Sentimental Analysis</ul>
						<ul>	<ul>	1.6.1 Industry Evolution</ul></ul>
						<ul>	<ul>	1.6.2 Research Demand</ul></ul>
						<ul>	<ul>	1.6.1 Understanding Contextual</ul></ul>
						<ul>	<ul>	1.6.5 Internet Marketing</ul></ul>
						<ul>1.7 Applications of Sentiment Analysis</ul>
						<ul>	<ul>	1.7.1 Word of Mounth (WOM)</ul></ul>
						<ul>	<ul>	1.7.2 Voice of Voters</ul></ul>
						<ul>	<ul>	1.7.3 Online Commerce</ul></ul>
						<ul>	<ul>	1.7.4 Voice of the Market (VOM)</ul></ul>
						<ul>	<ul>	1.7.5 Brand Reputation Management (BRM)</ul></ul>
						<ul>	<ul>	1.7.6 Government</ul></ul>
						<p>Chapter 2: Literature Review</p>			
						<p>Chapter 3: Problem Statement</p>
						<ul>3.1 Objectives</ul>
						<ul>3.2 Methodology</ul>
						<p>Chapter 4: Implementation </p>
						<ul>	4.1 Proposed Architecture</ul>
						<ul>	4.2 Twitter API</ul>
						<ul>	4.3 Data Collection</ul>
						<ul>	<ul>	4.3.1 Twitter Data</ul></ul>
						<ul>	<ul>	4.3.2 Training Data</ul></ul>
						<ul>4.4 Data Storage</ul>
						<ul>4.5 Data Pre-Processing</ul>
						<ul>4.6 Classification</ul>
						<ul>	<ul>	4.6.1 Feature Extraction</ul></ul>
						<p>Chapter 5: Results and Analysis</p>
						<ul>	5.1 Tweets Collected</ul>
						<ul>	5.2 Extracted Features</ul>
						<ul>	5.3 Classifier Accuracy for Training Data</ul>
						<ul>	5.4 Twitter Data Analysis</ul>
						<ul>	<ul>	5.4.1 Analysis for BJP</ul></ul>
						<ul>	<ul>	5.4.2 Analysis for AAP</ul></ul>
						<ul>	<ul>	5.4.3 Analysis for INC</ul></ul>
						<p>Chapter 6: Conclusion and Future Scope</p>
						<ul>	6.1 Conclusion</ul>
						<ul>	6.2 Future Scope</ul>
						
					</td>
				</tr>
				<tr>
					<th>POR QUÉ ES ÚTIL</th>
					<td>Este dcumento es útil para aprender a realizar un análisis del sentimiento utilizando NTLK en la red social de Twitter. Este tipo 
						de análisis puede resultar útiles por ejemplo para analizar la reacción que tiene una campaña publicitaria entre los usuarios, ver 
					que partido político tiene mayor imapcto positivo o negativo en la plataform, etc. </td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador de Microsft Academic, buscado articulos relacionados con NLTK</td>
				</tr>
				<tr>
					<th>URL</th>
					<td><a href=http://tudr.thapar.edu:8080/jspui/handle/10266/4273> http://tudr.thapar.edu:8080/jspui/handle/10266/4273</a></td>
				</tr>
			</table>		
			<h3 id=3.3>3.3 Software (herramientas, editores, etc. para desarrollar con la tecnología)</h3>
			<h4>3.3.1 Software 1</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>Sergio Sánchez Campo</td>
				</tr>
				<tr>
					<th>NOMBRE</th>
					<td>PyPLN</td>
				</tr>
				<tr>
					<th>PARA QUÉ SIRVE</th>
					<td>Es un pipeline que facilita el empleo de NLTK para el procesamiento de grandes cantidades de datos y además incorpora una interfaz web para facilitar el empleo de NLTK.</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td>Gratuito</td>
				</tr>
				<tr>
					<th>LICENCIA DE USO</th>
					<td><p>GPLv3</p>
						<p>GNU General Public License</p>
						<p>Copyright © 2007 Free Software Foundation, Inc</p>
					<p>Esta licencia permite que cualquier persona pueda copiar y distribuir copias textuales de este documento, pero no permite que el documento se modifique.</p>
						</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Buscando el Github de NLTK en el buscador de Google, y dentro del Github buscando en el apartado Proyectos</td>
				</tr>
				<tr>
					<th>URL SOFTWARE</th>
					<td><a href="https://github.com/NAMD/pypln.backend">https://github.com/NAMD/pypln.backend</a></td>
				</tr>
				<tr>
					<th>URL GUÍA DE USO</th>
					<td><a href="http://pypln.org/docs/">http://pypln.org/docs/</a></td>
				</tr>
			</table>
			<h4>3.3.2 Software 2</h4>
			<table>
				<tr>
					<th>ANALISTA</th>
					<td>David Ramos Fernández</td>
				</tr>
				<tr>
					<th>NOMBRE</th>
					<td>NLTK Trainer</td>
				</tr>
				<tr>
					<th>PARA QUÉ SIRVE</th>
					<td>Este software facilita el entrenamiento y evaluación de los objetos de NLTK.</td>
				</tr>
				<tr>
					<th>PRECIO</th>
					<td>Gratis</td>
				</tr>
				<tr>
					<th>LICENCIA DE USO</th>
					<td><p>Apache License 2.0 </p> 
					<p>© Copyright 2011, Jacob Perkins.</p>
					<p>PERMISOS: Uso comercial, realización de Modificaciones, Distribución, Patente de uso y uso privado.</p>
					<p>LIMITACIONES: No se puede hacer uso de la marca registrada, no estan sujetos a ninguna responsabilidad sobre el
						software y no tiene garantías.</p>
					<p><a href=https://github.com/japerk/nltk-trainer/blob/master/LICENSE>Documento de la licencia</a></p>
					</td>
				</tr>
				<tr>
					<th>CÓMO SE HA ENCONTRADO</th>
					<td>Mediante el buscador de Google, buscando en el github de NLTK</td>
				</tr>
				<tr>
					<th>URL SOFTWARE</th>
					<td><a href=https://nltk-trainer.readthedocs.io/en/latest> https://nltk-trainer.readthedocs.io/en/latest/</a></td>				</td>
				</tr>
				<tr>
					<th>URL GUÍA DE USO</th>
					<td><a href=https://nltk-trainer.readthedocs.io/en/latest> https://nltk-trainer.readthedocs.io/en/latest/</a></td>
				</tr>
			</table>			
			<section id="4">
				<h2>4. Conclusiones</h2>
				<p>Tras la realización de este trabajo, en términos generales no hemos encontrado grandes dificultades. Sin embargo, 
                    donde más dificultades hemos tenido es en la búsqueda y síntesis de las licencias relacionadas con los softwares.
                    Tambien hubo algunas complicaciones en la búsqueda de software de NLTK. Gracias a la realización de este trabajo hemos ampliado nuestros
                    conocimientos sobre los conceptos básicos de la tecnología del procesamiento del lenguaje natural y sus posibles usos.</p>
			</section>

	</main>

</body>

</html>
